{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST and some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAB6CAYAAAC7kYnCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF4GsG9AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a47131a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]\n",
    "\n",
    "# split train data in two parts\n",
    "X_pr = Xtrain[30000:60000, :, :]\n",
    "Y_pr = Ytrain[30000:60000]\n",
    "\n",
    "Xtrain = Xtrain[0:30000, :, :];\n",
    "Ytrain = Ytrain[0:30000]\n",
    "\n",
    "# DOWNSAMPLE THE IMAGES\n",
    "factor = 0.25\n",
    "\n",
    "Xtrain_down = np.ones((Xtrain.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    Xtrain_down[i, :, :] = imresize(Xtrain[i,:,:], factor)\n",
    "\n",
    "Xtest_down = np.ones((Xtest.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtest.shape[0]):\n",
    "    Xtest_down[i,:,:] = imresize(Xtest[i,:,:], factor)\n",
    "\n",
    "    \n",
    "X_pr_down = np.ones((X_pr.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(X_pr.shape[0]):\n",
    "    X_pr_down[i,:,:] = imresize(X_pr[i,:,:], factor)\n",
    "\n",
    "    \n",
    "# VECTORIZE IMAGES\n",
    "Xtrain_down = Xtrain_down.reshape(Xtrain.shape[0], int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtest_down  = Xtest_down.reshape(ntest, int(xdim*factor)**2).astype('float32') / 255\n",
    "X_pr_down   = X_pr_down.reshape(X_pr.shape[0], int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtrain      = Xtrain.reshape(Xtrain.shape[0], xdim**2).astype('float32') / 255\n",
    "Xtest       = Xtest.reshape(ntest, xdim**2).astype('float32') / 255\n",
    "\n",
    "# Categorical labels\n",
    "Ytrain_cat = np_utils.to_categorical(Ytrain, 10)\n",
    "Ytest_cat = np_utils.to_categorical(Ytest, 10)\n",
    "\n",
    "# VISUALIZATION 20 RANDOM TRAINING SAMPLES\n",
    "# Create 20 subplots\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        axes[i][j].imshow(Xtrain_down[np.random.randint(0, 3000),:].reshape(int(xdim*factor), \n",
    "                          int(ydim*factor)), cmap='gray_r', interpolation='nearest')\n",
    "        axes[i][j].set_xticks([])\n",
    "        axes[i][j].set_yticks([])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN A FULLY-CONNECTED NN WITH 4 \"LINEAR\" HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30000/30000 [==============================] - 6s - loss: 0.4971 - acc: 0.8487     \n",
      "Epoch 2/50\n",
      "30000/30000 [==============================] - 3s - loss: 0.4024 - acc: 0.8801     \n",
      "Epoch 3/50\n",
      "30000/30000 [==============================] - 3s - loss: 0.3936 - acc: 0.8850     \n",
      "Epoch 4/50\n",
      "30000/30000 [==============================] - 3s - loss: 0.3903 - acc: 0.8842     \n",
      "Epoch 5/50\n",
      "30000/30000 [==============================] - 3s - loss: 0.3873 - acc: 0.8849     \n",
      "Epoch 6/50\n",
      "30000/30000 [==============================] - 3s - loss: 0.3847 - acc: 0.8864     \n",
      "Epoch 7/50\n",
      "30000/30000 [==============================] - 3s - loss: 0.3799 - acc: 0.8881     \n",
      "Epoch 8/50\n",
      "30000/30000 [==============================] - 3s - loss: 0.3822 - acc: 0.8893     \n",
      "Epoch 9/50\n",
      "30000/30000 [==============================] - 3s - loss: 0.3765 - acc: 0.8907     \n",
      "Epoch 10/50\n",
      "21152/30000 [====================>.........] - ETA: 0s - loss: 0.3718 - acc: 0.8919"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(int(xdim*factor)**2,)))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "with tf.device('/gpu:1'):\n",
    "    model.fit(Xtrain_down, Ytrain_cat, nb_epoch=50, batch_size=32)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(Xtest_down, Ytest_cat, verbose=0)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# # calculate predictions\n",
    "# Ypredict = model.predict(Xtest)\n",
    "# # round predictions\n",
    "# rounded = [round(x[0]) for x in Ypredict]\n",
    "# print(rounded)\n",
    "\n",
    "# Save the model\n",
    "model.save('linear_nn.h5')\n",
    "\n",
    "# GET THE OUTPUT OF EACH LAYER AFTER TRAINING\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function\n",
    "layer_outs = functor([X_pr_down, 1.])                       # compute on 2nd training set\n",
    "layer_outs_test = functor([Xtest_down, 1.])                 # compute on test set\n",
    "#print(layer_outs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subsample and do xgboost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'layer_outs_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5e8d325090d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m#print('#neuron, #iteratin, subnetsize: ', iN,it,subnetSize[ss])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mxg_train\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_subsample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_subsample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mxg_test\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_outs_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_outs_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mwatchlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;31m# train XGboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layer_outs_test' is not defined"
     ]
    }
   ],
   "source": [
    "from copy import copy, deepcopy\n",
    "from RE_PartialRecData import RE_PartialRecData\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "params = {}\n",
    "# use softmax multi-class classification 'multi:softmax'\n",
    "# use linear regression 'reg:linear'\n",
    "params['objective'] = 'reg:linear'\n",
    "# scale weight of positive examples\n",
    "params['eta'] = 0.4\n",
    "params['max_depth'] = 6\n",
    "params['silent'] = 1\n",
    "params['nthread'] = 4\n",
    "# params['num_class'] = 10\n",
    "num_round=5\n",
    "\n",
    "# how many recordings?\n",
    "nRecordings = 10\n",
    "# how many neurons from the firs hidden layer?\n",
    "subnetSize = [2**x for x in range(8)]\n",
    "nSubnetSize = len(subnetSize)\n",
    "# which layers?\n",
    "# how many samples per recording?\n",
    "nSamples = np.divide(int(X_pr_down.shape[0]/nRecordings),subnetSize)\n",
    "# how many iterations\n",
    "nIterations = 50\n",
    "\n",
    "# baseline prediction error\n",
    "#bl = np.std(layer_outs_test[oLayer]-np.mean(layer_outs_test[oLayer]));\n",
    "\n",
    "oLayer = len(layer_outs)-1  # index of output layer\n",
    "nOutNeurons = layer_outs[oLayer].shape[1]\n",
    "rmses = np.zeros([nIterations, nOutNeurons, nSubnetSize])\n",
    "\n",
    "for ss in range(nSubnetSize):\n",
    "    nLayerNeurons = [subnetSize[ss], 0, 0, 0, 10]\n",
    "    print(subnetSize[ss])\n",
    "    for it in range(nIterations):\n",
    "        # copy data\n",
    "        layer_outputs = deepcopy(layer_outs)\n",
    "        # subsample\n",
    "        X_subsample, Y_subsample = RE_PartialRecData(layer_outputs, nLayerNeurons, nRecordings, nSamples[ss])\n",
    "        #print('# nan neurons: ',np.count_nonzero(np.isnan(X_subsample[:3000,:]).sum(axis=0)))\n",
    "        # prepare data for xgboost\n",
    "        for iN in range(nOutNeurons):\n",
    "            #print('#neuron, #iteratin, subnetsize: ', iN,it,subnetSize[ss])\n",
    "            xg_train  = xgb.DMatrix(X_subsample, label=Y_subsample[:, iN])\n",
    "            xg_test   = xgb.DMatrix(layer_outs_test[0], label=layer_outs_test[3][:,iN])\n",
    "            watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "            # train XGboost\n",
    "            bst = xgb.train(params, xg_train, num_round, watchlist, verbose_eval=True)\n",
    "            # get predictions\n",
    "            pred = bst.predict(xg_test)\n",
    "            rmses[it,iN,ss] = np.sqrt(np.mean(np.square([(pred[i] - layer_outs_test[3][:,iN][i]) \n",
    "                                         for i in range(len(layer_outs_test[3][:,1]))])))\n",
    "            #print ('predicting, RMSE=%f' %rmses[it, iN, ss])\n",
    "            \n",
    "\n",
    "# save the rmse's\n",
    "with open('RMSE_Layer1_Linear.dat','wb') as f:\n",
    "    pickle.dump(rmses, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
