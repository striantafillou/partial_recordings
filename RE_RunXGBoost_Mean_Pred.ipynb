{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = 'NN'\n",
    "\n",
    "import pickle\n",
    "with open('results/' + nn + '_layer_outputs.dat','rb') as f:\n",
    "    layer_outs,layer_outs_test= pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load recording and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from scipy.misc import imresize\n",
    "\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]\n",
    "\n",
    "# Recording data\n",
    "X_pr = Xtrain[30000:60000, :, :]\n",
    "Y_pr = Ytrain[30000:60000]\n",
    "\n",
    "\n",
    "# downsample\n",
    "factor = 1\n",
    "if factor<1:\n",
    "    Xtest_down = np.ones((Xtest.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "    for i in range(Xtest.shape[0]):\n",
    "        Xtest_down[i,:,:] = imresize(Xtest[i,:,:], factor)\n",
    "\n",
    "    X_pr_down = np.ones((X_pr.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "    for i in range(X_pr.shape[0]):\n",
    "        X_pr_down[i,:,:] = imresize(X_pr[i,:,:], factor)\n",
    "else:\n",
    "    Xtest_down = Xtest\n",
    "    X_pr_down = X_pr\n",
    "    \n",
    "# VECTORIZE IMAGES\n",
    "Xtest_down = Xtest_down.reshape(ntest, int(xdim*factor)**2).astype('float32') / 255\n",
    "X_pr_down = X_pr_down.reshape(X_pr_down.shape[0], int(xdim*factor)**2).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run XGBOOST and Average Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2f55e8d20082>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mnSubnetSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubnetSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# how many samples per recording?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mnSamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pr_down\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnRecordings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubnetSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;31m# how many iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mnIterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from copy import copy, deepcopy\n",
    "from RE_PartialRecData import RE_PartialRecData\n",
    "from RE_PartialRecData2 import RE_PartialRecData2\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "params = {}\n",
    "# use softmax multi-class classification 'multi:softmax'\n",
    "# use linear regression 'reg:linear'\n",
    "params['objective'] = 'reg:linear'\n",
    "# scale weight of positive examples\n",
    "params['eta'] = 0.5               # Makes the model more robust by shrinking the weights on each step (0.01-0.2)\n",
    "params['max_depth'] = 6           # Used to control over-fitting as higher depth will allow model to learn relations \n",
    "                                  # very specific to a particular sample. (3-10)\n",
    "params['silent'] = 1\n",
    "params['nthread'] = 4\n",
    "# params['num_class'] = 10\n",
    "num_round = 5\n",
    "\n",
    "# how many recordings?\n",
    "#nRecordings = 10\n",
    "# how many neurons from the firs hidden layer?\n",
    "subnetSize = [2**x for x in range(8)]\n",
    "nSubnetSize = len(subnetSize)\n",
    "# how many samples per recording?\n",
    "nSamples = np.divide(int(X_pr_down.shape[0]/nRecordings),subnetSize)*100\n",
    "# how many iterations\n",
    "nIterations = 5\n",
    "\n",
    "\n",
    "\n",
    "# baseline prediction error\n",
    "#bl = np.std(layer_outs_test[oLayer]-np.mean(layer_outs_test[oLayer]));\n",
    "\n",
    "oLayer = len(layer_outs)-1  # index of output layer\n",
    "nOutNeurons = layer_outs[oLayer].shape[1]\n",
    "rmses = np.zeros([nIterations, nOutNeurons, nSubnetSize])\n",
    "\n",
    "for iLayer in range(0, len(layer_outs)-1, 2):\n",
    "    print('Layer ', iLayer)\n",
    "    for ss in range(nSubnetSize):\n",
    "        #r_coefs =np.zeros((nIterations, 10, 128))\n",
    "        #nLayerNeurons = [subnetSize[ss], 0, 0, 0, 10]\n",
    "        nLayerNeurons = subnetSize[ss]\n",
    "        print(subnetSize[ss])\n",
    "        for it in range(nIterations):\n",
    "            # copy data - is this necessary?\n",
    "            layer_outputs = deepcopy(layer_outs)\n",
    "            rmses_rec = np.zeros((nRecordings, nOutNeurons))\n",
    "            for iRec in range(nRecordings):\n",
    "                # subsample\n",
    "                X_subsample, Y_subsample = RE_PartialRecData2(layer_outputs[iLayer], layer_outputs[oLayer], \\\n",
    "                                                              nLayerNeurons, 1, nSamples[ss])\n",
    "                # impute X_subsample with mean value, apply imputation to test set\n",
    "                imp =preprocessing.Imputer(missing_values='NaN', strategy='mean')\n",
    "                impf =imp.fit(X_subsample)\n",
    "                X_new = impf.transform(X_subsample)\n",
    "                X_test_new= impf.transform(layer_outs_test[iLayer])\n",
    "                for iN in range(nOutNeurons):\n",
    "                    xg_train  = xgb.DMatrix(X_new, label=Y_subsample[:, iN])\n",
    "                    xg_test   = xgb.DMatrix(X_test_new, label=layer_outs_test[oLayer][:, iN])\n",
    "                    watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "                    # train XGboost\n",
    "                    bst = xgb.train(params, xg_train, num_round, watchlist, verbose_eval=False)\n",
    "                    # get predictions\n",
    "                    pred = bst.predict(xg_test)\n",
    "                    rmses_rec[iRec, iN] = np.sqrt(np.mean((bst.predict(xg_test)-layer_outs_test[oLayer][:,iN])**2))\n",
    " \n",
    "            rmses[it,:,ss] = np.mean(rmses_rec, axis=0)\n",
    "\n",
    "            print ('predicting, mean RMSEs=%f' %np.mean(rmses[it, :, ss]))\n",
    "\n",
    "    fName = 'results/XGBMP_RMSES_Layer'+str(iLayer) + 'nRec' + str(nRecordings) + nn + '.dat'\n",
    "    # save the rmse's\n",
    "    with open(fName,'wb') as f:\n",
    "        pickle.dump(rmses, f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.25930961,  0.2877039 ,  0.24338835,  0.19015548,  0.08806124,\n",
       "          0.05877062,  0.05289189,  0.05355992],\n",
       "        [ 0.30897775,  0.26999986,  0.25167819,  0.18596766,  0.10064565,\n",
       "          0.05581182,  0.05035044,  0.0462843 ],\n",
       "        [ 0.29243189,  0.28015442,  0.22754942,  0.14690283,  0.15105976,\n",
       "          0.06799057,  0.0596003 ,  0.06217328],\n",
       "        [ 0.2957277 ,  0.29103321,  0.22947572,  0.17333468,  0.13385403,\n",
       "          0.06885572,  0.06218535,  0.05884095],\n",
       "        [ 0.27195448,  0.28204014,  0.2625579 ,  0.24224806,  0.11764654,\n",
       "          0.06717136,  0.05174606,  0.04718388],\n",
       "        [ 0.25132943,  0.27231364,  0.2382123 ,  0.20574926,  0.08450492,\n",
       "          0.07124571,  0.04917222,  0.04798445],\n",
       "        [ 0.28003681,  0.28402947,  0.24349586,  0.22440704,  0.15213971,\n",
       "          0.08619285,  0.05936144,  0.05941854],\n",
       "        [ 0.29837527,  0.28728029,  0.27871374,  0.18759961,  0.12662722,\n",
       "          0.0784798 ,  0.06156598,  0.05855538],\n",
       "        [ 0.27808591,  0.26876782,  0.22511987,  0.22821033,  0.12585118,\n",
       "          0.06950629,  0.06920627,  0.07002033],\n",
       "        [ 0.28296085,  0.29155409,  0.28544864,  0.21987802,  0.1653581 ,\n",
       "          0.07913393,  0.05685091,  0.05003569]],\n",
       "\n",
       "       [[ 0.28482233,  0.27419843,  0.24287578,  0.18133383,  0.07215734,\n",
       "          0.06885457,  0.05196788,  0.05266918],\n",
       "        [ 0.30951534,  0.27590865,  0.17537321,  0.18290402,  0.08616222,\n",
       "          0.07309236,  0.05218898,  0.04991095],\n",
       "        [ 0.28657246,  0.28142222,  0.25503238,  0.16369757,  0.12486916,\n",
       "          0.06620938,  0.05736876,  0.06198349],\n",
       "        [ 0.2988162 ,  0.27409726,  0.24771055,  0.23959201,  0.12724282,\n",
       "          0.06556068,  0.05928013,  0.05990149],\n",
       "        [ 0.25545406,  0.25593597,  0.20579546,  0.16406677,  0.13760433,\n",
       "          0.08406962,  0.05734813,  0.04584278],\n",
       "        [ 0.27871252,  0.24971062,  0.25546076,  0.18408084,  0.08556761,\n",
       "          0.06386339,  0.04727121,  0.04672469],\n",
       "        [ 0.26976273,  0.28079264,  0.23132547,  0.22425748,  0.1370559 ,\n",
       "          0.06722571,  0.06075542,  0.05922704],\n",
       "        [ 0.27397604,  0.28815142,  0.22599782,  0.20119566,  0.10994846,\n",
       "          0.07958169,  0.0637559 ,  0.05585632],\n",
       "        [ 0.2588908 ,  0.27486771,  0.24919979,  0.16983957,  0.10811297,\n",
       "          0.08094517,  0.06630155,  0.06957645],\n",
       "        [ 0.29163269,  0.26358908,  0.23904342,  0.19618557,  0.12042195,\n",
       "          0.08591683,  0.06003802,  0.04923816]],\n",
       "\n",
       "       [[ 0.27319858,  0.288345  ,  0.26370971,  0.17208988,  0.12393923,\n",
       "          0.06225168,  0.05323928,  0.05435305],\n",
       "        [ 0.30169179,  0.23318028,  0.25296368,  0.1928224 ,  0.10289983,\n",
       "          0.06071036,  0.0573677 ,  0.04626023],\n",
       "        [ 0.29601231,  0.26878939,  0.24281002,  0.21724103,  0.11782012,\n",
       "          0.07107357,  0.0588078 ,  0.06012329],\n",
       "        [ 0.21462932,  0.25252676,  0.20928004,  0.20988316,  0.13727832,\n",
       "          0.08086776,  0.05927316,  0.05809682],\n",
       "        [ 0.29540877,  0.28587433,  0.28923538,  0.20868173,  0.10399782,\n",
       "          0.07695402,  0.05139152,  0.04702667],\n",
       "        [ 0.2719368 ,  0.26939152,  0.24110217,  0.19289558,  0.10144453,\n",
       "          0.07507414,  0.04788141,  0.0457864 ],\n",
       "        [ 0.29215138,  0.28957977,  0.27195762,  0.20743544,  0.12536751,\n",
       "          0.08540513,  0.0735455 ,  0.05741531],\n",
       "        [ 0.29902725,  0.25948012,  0.25907147,  0.21773575,  0.11765903,\n",
       "          0.07823517,  0.06086603,  0.05840826],\n",
       "        [ 0.29188299,  0.2692499 ,  0.23587928,  0.19774077,  0.09681735,\n",
       "          0.09549683,  0.06785725,  0.06862489],\n",
       "        [ 0.29606442,  0.28858759,  0.27203874,  0.20150655,  0.0922289 ,\n",
       "          0.07580654,  0.0577169 ,  0.05050972]],\n",
       "\n",
       "       [[ 0.24277515,  0.25640746,  0.2206187 ,  0.16537966,  0.15306297,\n",
       "          0.0528818 ,  0.05101596,  0.05264203],\n",
       "        [ 0.29194388,  0.28031261,  0.26019986,  0.17880046,  0.13381839,\n",
       "          0.0628962 ,  0.05852915,  0.04611124],\n",
       "        [ 0.29311719,  0.25673096,  0.22640235,  0.21480664,  0.136711  ,\n",
       "          0.06559329,  0.05685281,  0.06202022],\n",
       "        [ 0.29674979,  0.27914476,  0.20758898,  0.2059823 ,  0.17729953,\n",
       "          0.06143092,  0.0585762 ,  0.05712795],\n",
       "        [ 0.28987976,  0.27329352,  0.26199355,  0.22214377,  0.11778112,\n",
       "          0.08362162,  0.05281737,  0.04568768],\n",
       "        [ 0.27493542,  0.27262207,  0.25279977,  0.19876642,  0.10830324,\n",
       "          0.05198671,  0.0501087 ,  0.04574556],\n",
       "        [ 0.29098891,  0.27533237,  0.25930656,  0.24037374,  0.13293088,\n",
       "          0.07681347,  0.06210433,  0.05976936],\n",
       "        [ 0.26968303,  0.2931921 ,  0.22323505,  0.17653582,  0.11095986,\n",
       "          0.07250802,  0.06164739,  0.0565953 ],\n",
       "        [ 0.28203322,  0.27687888,  0.25095968,  0.15110293,  0.12049731,\n",
       "          0.07412601,  0.06715909,  0.06951971],\n",
       "        [ 0.28044219,  0.26253994,  0.2659162 ,  0.17349009,  0.14096903,\n",
       "          0.06851924,  0.0585033 ,  0.04925874]],\n",
       "\n",
       "       [[ 0.27531049,  0.24046864,  0.2726268 ,  0.16347489,  0.08526992,\n",
       "          0.06056238,  0.05346454,  0.05404609],\n",
       "        [ 0.31260956,  0.26101126,  0.25726853,  0.14080184,  0.11632271,\n",
       "          0.0649569 ,  0.0604576 ,  0.04595293],\n",
       "        [ 0.28761942,  0.28285207,  0.25736487,  0.22011124,  0.11019263,\n",
       "          0.08152947,  0.05673978,  0.0631802 ],\n",
       "        [ 0.27490019,  0.27416838,  0.24745268,  0.18102368,  0.12188161,\n",
       "          0.07279226,  0.05780739,  0.05609933],\n",
       "        [ 0.28870675,  0.25608535,  0.2612722 ,  0.20257291,  0.15056963,\n",
       "          0.08707399,  0.04771175,  0.04899786],\n",
       "        [ 0.23889086,  0.2643275 ,  0.24954195,  0.20670111,  0.11450259,\n",
       "          0.05820205,  0.04880467,  0.04469549],\n",
       "        [ 0.28487139,  0.27806126,  0.2690671 ,  0.23299652,  0.14907225,\n",
       "          0.09528259,  0.05966264,  0.05806137],\n",
       "        [ 0.28867849,  0.26280413,  0.26006066,  0.15513178,  0.15099788,\n",
       "          0.07500346,  0.0594806 ,  0.05859403],\n",
       "        [ 0.28735329,  0.25474731,  0.23490878,  0.17163846,  0.1118502 ,\n",
       "          0.0817689 ,  0.06634562,  0.06829493],\n",
       "        [ 0.2963311 ,  0.27581377,  0.24674908,  0.16982975,  0.11559518,\n",
       "          0.08865047,  0.05453992,  0.04790922]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
