{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 5103)\n",
      "No traceback available to show.\n",
      "usage: __main__.py [-h] -1 IMAGE\n",
      "__main__.py: error: argument -1/--image is required\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "%tb\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to the input image\")\n",
    "ap.add_argument(\"-model\", \"--model\", type=str, default=\"vgg16\", help=\"name of pre-trained network to use\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-1\",\"--image\", required = True, help = \"Path to the image\")\n",
    "    args = vars(ap.parse_args())\n",
    "    print args['image']\n",
    "\n",
    "# define a dictionary that maps model names to their classes\n",
    "# inside Keras\n",
    "MODELS = {\"vgg16\": VGG16}\n",
    " \n",
    "# initialize the input image shape (224x224 pixels) along with\n",
    "# the pre-processing function (this might need to be changed\n",
    "# based on which model we use to classify our image)\n",
    "inputShape = (224, 224)\n",
    "preprocess = imagenet_utils.preprocess_input\n",
    " \n",
    "# load our the network weights from disk (NOTE: if this is the\n",
    "# first time you are running this script for a given network, the\n",
    "# weights will need to be downloaded first -- depending on which\n",
    "# network you are using, the weights can be 90-575MB, so be\n",
    "# patient; the weights will be cached and subsequent runs of this\n",
    "# script will be *much* faster)\n",
    "print(\"[INFO] loading {}...\".format('vgg16'))\n",
    "Network = MODELS['vgg16']\n",
    "model = Network(weights=\"imagenet\")\n",
    "\n",
    "# load the input image using the Keras helper utility while ensuring\n",
    "# the image is resized to `inputShape`, the required input dimensions\n",
    "# for the ImageNet pre-trained network\n",
    "print(\"[INFO] loading and pre-processing image...\")\n",
    "image = load_img(args[\"image\"], target_size=inputShape)\n",
    "image = img_to_array(image)\n",
    " \n",
    "# our input image is now represented as a NumPy array of shape\n",
    "# (inputShape[0], inputShape[1], 3) however we need to expand the\n",
    "# dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
    "# so we can pass it through thenetwork\n",
    "image = np.expand_dims(image, axis=0)\n",
    " \n",
    "# pre-process the image using the appropriate function based on the\n",
    "# model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
    "image = preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # import the necessary packages\n",
    "# from keras.preprocessing import image as image_utils\n",
    "# from imagenet_utils import decode_predictions\n",
    "# from imagenet_utils import preprocess_input\n",
    "# from vgg16 import VGG16\n",
    "# import numpy as np\n",
    "# import argparse\n",
    "# import cv2\n",
    " \n",
    "# # construct the argument parse and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to the input image\")\n",
    "# args = vars(ap.parse_args())\n",
    " \n",
    "# # load the original image via OpenCV so we can draw on it and display\n",
    "# # it to our screen later\n",
    "# orig = cv2.imread(args[\"image\"])\n",
    "\n",
    "# # load the input image using the Keras helper utility while ensuring\n",
    "# # that the image is resized to 224x224 pxiels, the required input\n",
    "# # dimensions for the network -- then convert the PIL image to a\n",
    "# # NumPy array\n",
    "# print(\"[INFO] loading and preprocessing image...\")\n",
    "# image = image_utils.load_img(args[\"image\"], target_size=(224, 224))\n",
    "# image = image_utils.img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
