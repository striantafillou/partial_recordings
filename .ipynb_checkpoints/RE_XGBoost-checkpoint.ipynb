{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# Load MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# *** DOWNSAMPLE THE IMAGES ***\n",
    "factor = 1/4\n",
    "\n",
    "Xtrain_down = np.ones((ntrain, int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(ntrain):\n",
    "    Xtrain_down[i, :, :] = imresize(Xtrain[i,:,:], factor)\n",
    "\n",
    "Xtest_down = np.ones((ntest, int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(ntest):\n",
    "    Xtest_down[i,:,:] = imresize(Xtest[i,:,:], factor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# *** VECTORIZE IMAGES ***\n",
    "Xtrain_down = Xtrain_down.reshape(ntrain, int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtest_down  = Xtest_down.reshape(ntest, int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtrain      = Xtrain.reshape(ntrain, xdim**2).astype('float32') / 255\n",
    "Xtest       = Xtest.reshape(ntest, xdim**2).astype('float32') / 255\n",
    "# Categorical labels\n",
    "# Ytrain = np_utils.to_categorical(Ytrain, 10)\n",
    "# Ytest  = np_utils.to_categorical(Ytest, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.1321\ttest-merror:0.1446\n",
      "[1]\ttrain-merror:0.105\ttest-merror:0.1185\n",
      "[2]\ttrain-merror:0.091467\ttest-merror:0.1062\n",
      "[3]\ttrain-merror:0.084317\ttest-merror:0.0965\n",
      "[4]\ttrain-merror:0.0803\ttest-merror:0.0914\n",
      "predicting, classification error=0.091400\n",
      "[0]\ttrain-merror:0.1321\ttest-merror:0.1446\n",
      "[1]\ttrain-merror:0.105\ttest-merror:0.1185\n",
      "[2]\ttrain-merror:0.091467\ttest-merror:0.1062\n",
      "[3]\ttrain-merror:0.084317\ttest-merror:0.0965\n",
      "[4]\ttrain-merror:0.0803\ttest-merror:0.0914\n",
      "predicting, classification error=0.091400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xg_train = xgb.DMatrix(Xtrain, label=Ytrain)\n",
    "xg_test  = xgb.DMatrix(Xtest, label=Ytest)\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "\n",
    "# setup parameters for xgboost\n",
    "params = {}\n",
    "# use softmax multi-class classification\n",
    "params['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "params['eta'] = 0.1\n",
    "params['max_depth'] = 6\n",
    "params['silent'] = 1\n",
    "params['nthread'] = 4\n",
    "params['num_class'] = 10\n",
    "\n",
    "num_round = 5\n",
    "bst = xgb.train(params, xg_train, num_round, watchlist );\n",
    "# get prediction\n",
    "pred = bst.predict( xg_test );\n",
    "print ('predicting, classification error=%f' % (sum( int(pred[i]) != Ytest[i] \n",
    "                                                    for i in range(len(Ytest))) / float(len(Ytest)) ))\n",
    "\n",
    "# # do the same thing again, but output probabilities\n",
    "# params['objective'] = 'multi:softprob'\n",
    "# bst = xgb.train(params, xg_train, num_round, watchlist );\n",
    "# # Note: this convention has been changed since xgboost-unity\n",
    "# # get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "# yprob = bst.predict( xg_test ).reshape( Ytest.shape[0], 10 )\n",
    "# ylabel = np.argmax(yprob, axis=1)\n",
    "\n",
    "# print ('predicting, classification error=%f' % (sum( int(ylabel[i]) != Ytest[i] \n",
    "#                                                     for i in range(len(Ytest))) / float(len(Ytest)) ))\n",
    "\n",
    "# # print(\"total %i/%i\" % (np.sum(labels == preds), len(preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Control Overfitting\n",
    "\n",
    "When you observe high training accuracy, but low tests accuracy, it is likely that you encounter overfitting problem.\n",
    "There are in general two ways that you can control overfitting in xgboost\n",
    "\n",
    "- The first way is to directly control model complexity\n",
    "This include max_depth, min_child_weight and gamma\n",
    "\n",
    "- The second way is to add randomness to make training robust to noise\n",
    "This include subsample, colsample_bytree\n",
    "You can also reduce stepsize eta, but needs to remember to increase num_round when you do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Handle Imbalanced Dataset\n",
    "\n",
    "For common cases such as ads clickthrough log, the dataset is extremely imbalanced. This can affect the training of xgboost model, and there are two ways to improve it.\n",
    "\n",
    "- If you care only about the ranking order (AUC) of your prediction\n",
    "Balance the positive and negative weights, via scale_pos_weight\n",
    "Use AUC for evaluation\n",
    "\n",
    "- If you care about predicting the right probability\n",
    "In such a case, you cannot re-balance the dataset\n",
    "In such a case, set parameter max_delta_step to a finite number (say 1) will help converge"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
