{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# Load MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]\n",
    "\n",
    "# split train data in two\n",
    "X_pr = Xtrain[30000:60000, :, :]\n",
    "Y_pr = Ytrain[30000:60000]\n",
    "\n",
    "Xtrain = Xtrain[0:30001, :, :];\n",
    "Ytrain = Ytrain[0:30001]\n",
    "\n",
    "# downsample\n",
    "factor = 0.25\n",
    "\n",
    "Xtrain_down = np.ones((Xtrain.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    Xtrain_down[i, :, :] = imresize(Xtrain[i,:,:], factor)\n",
    "\n",
    "Xtest_down = np.ones((Xtest.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtest.shape[0]):\n",
    "    Xtest_down[i,:,:] = imresize(Xtest[i,:,:], factor)\n",
    "\n",
    "    \n",
    "X_pr_down = np.ones((X_pr.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(X_pr.shape[0]):\n",
    "    X_pr_down[i,:,:] = imresize(X_pr[i,:,:], factor)\n",
    "    \n",
    "# *** VECTORIZE IMAGES ***\n",
    "Xtrain_down = Xtrain_down.reshape(Xtrain_down.shape[0], int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtest_down = Xtest_down.reshape(ntest, int(xdim*factor)**2).astype('float32') / 255\n",
    "X_pr_down = X_pr_down.reshape(X_pr_down.shape[0], int(xdim*factor)**2).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load NN and get output values\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('nn.h5')\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function\n",
    "\n",
    "# Testing: layer_outs is a list with 4 data sets\n",
    "layer_outs = functor([X_pr_down, 1.])\n",
    "\n",
    "layer_outs_test= functor([Xtest_down, 1.])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'X' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e281e1fd79f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mlayer_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# subsample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRE_PartialRecData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnLayerNeurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnRecordings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnSamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;31m# prepare data for xgboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mxg_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_pr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/striant/partial_recordings/RE_PartialRecData.pyc\u001b[0m in \u001b[0;36mRE_PartialRecData\u001b[1;34m(layer_outputs, nLayerNeurons, nRecordings, nSamples)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'X' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# subsample and do xgboost regression\n",
    "from copy import copy, deepcopy\n",
    "from RE_PartialRecData import RE_PartialRecData\n",
    "\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# setup parameters for xgboost\n",
    "params = {}\n",
    "# use softmax multi-class classification\n",
    "params['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "params['eta'] = 0.1\n",
    "params['max_depth'] = 6\n",
    "params['silent'] = 1\n",
    "params['nthread'] = 4\n",
    "params['num_class'] = 10\n",
    "num_round=5\n",
    "\n",
    "# how many recordings?\n",
    "nRecordings = 10\n",
    "# how many neurons from the firs hidden layer?\n",
    "subnetSize = range(49)+1\n",
    "nSubnetSize = len(subnetSize)\n",
    "# which layers?\n",
    "# how many samples per recording?\n",
    "nSamples = X_pr_down.shape[0]/nRecordings\n",
    "# how many iterations\n",
    "nIterations = 100\n",
    "\n",
    "oLayer = len(layer_outs)-1\n",
    "nOutNeurons = layer_outs[oLayer].shape[1]\n",
    "rmses = np.zeros([nIterations, nOutNeurons, nSubnetSize])\n",
    "\n",
    "for ss in range(nSubnetSize):\n",
    "    nLayerNeurons = [subnetSize[ss], 0, 0, 10]\n",
    "    for it in range(nIterations):\n",
    "        #print(nLayerNeurons, iter)\n",
    "        # copy data\n",
    "        layer_outputs = deepcopy(layer_outs)\n",
    "        # subsample\n",
    "        X= RE_PartialRecData(layer_outputs, nLayerNeurons, nRecordings, nSamples)\n",
    "        # prepare data for xgboost\n",
    "        xg_train = xgb.DMatrix(X, label=Y_pr)\n",
    "        xg_test  = xgb.DMatrix(layer_outs_test[0], label=Ytest)\n",
    "        watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "        for iN in range(nOutNeurons):\n",
    "            print(iN)\n",
    "            xg_train = xgb.DMatrix(X, label=layer_outs[3][:,iN])\n",
    "            xg_test  = xgb.DMatrix(layer_outs_test[0], label=layer_outs_test[3][:,iN])\n",
    "            watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "\n",
    "            bst = xgb.train(params, xg_train, num_round, watchlist);\n",
    "            # get prediction\n",
    "            pred = bst.predict( xg_test );\n",
    "            rmses[it,iN,ss]=np.sqrt(sum(np.square(pred[i] -layer_outs_test[3][:,1][i]) \n",
    "                                                    for i in range(len(layer_outs_test[3][:,1]))) / float(len(layer_outs_test[3][:,1])))\n",
    "            print ('predicting, RMSE=%f' %rmses[it, iN,ss ] )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subnetSize = range(49)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'X' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7e2298c76d7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRE_PartialRecData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnLayerNeurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnRecordings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnSamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/striant/partial_recordings/RE_PartialRecData.pyc\u001b[0m in \u001b[0;36mRE_PartialRecData\u001b[1;34m(layer_outputs, nLayerNeurons, nRecordings, nSamples)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'X' referenced before assignment"
     ]
    }
   ],
   "source": [
    "X= RE_PartialRecData(layer_outputs, nLayerNeurons, nRecordings, nSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y[1:10, :\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oLayer = len(layer_outs)-1\n",
    "oLayer\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
