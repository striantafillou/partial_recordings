{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# Load MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Downsample the images by factor 2\n",
    "# ratio = 1/2\n",
    "\n",
    "# Xtrain_down = np.ones((ntrain, xdim*ratio, ydim*ratio))\n",
    "# for i in range(ntrain):\n",
    "#     Xtrain_down[i, :, :] = imresize(Xtrain[i,:,:], downsample_ratio)\n",
    "\n",
    "# Xtest_down = np.ones((ntest, xdim*ratio, ydim*ratio))\n",
    "# for i in range(ntest):\n",
    "#     Xtest_down[i,:,:] = imresize(Xtest[i,:,:], downsample_ratio)\n",
    "\n",
    "# plt.imshow(Xtrain[1,:,:])\n",
    "# plt.imshow(Xtrain_down[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the input images\n",
    "# Xtrain_down = Xtrain_down.reshape(ntrain, xdim*ratio**2).astype('float32') / 255\n",
    "# Xtest_down = Xtest_down.reshape(ntest, xdim*ratio**2).astype('float32') / 255\n",
    "Xtrain = Xtrain.reshape(ntrain, xdim**2).astype('float32') / 255\n",
    "Xtest = Xtest.reshape(ntest, xdim**2).astype('float32') / 255\n",
    "Ytrain = np_utils.to_categorical(Ytrain, 10)\n",
    "Ytest = np_utils.to_categorical(Ytest, 10)\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 10s - loss: 0.2265 - acc: 0.9311    \n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 9s - loss: 0.1059 - acc: 0.9680     \n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 9s - loss: 0.0786 - acc: 0.9753     \n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 9s - loss: 0.0622 - acc: 0.9809     \n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 11s - loss: 0.0518 - acc: 0.9838    \n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 12s - loss: 0.0459 - acc: 0.9855    \n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 9s - loss: 0.0388 - acc: 0.9877     \n",
      "Epoch 8/25\n",
      "50768/60000 [========================>.....] - ETA: 1s - loss: 0.0333 - acc: 0.9895"
     ]
    }
   ],
   "source": [
    "##### TRAIN A FULLY-CONNECTED NN WITH TWO HIDDEN LAYERS\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(xdim**2,), activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(Xtrain, Ytrain, nb_epoch=25, batch_size=16)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# # calculate predictions\n",
    "# predictions = model.predict(Xtest)\n",
    "# # round predictions\n",
    "# rounded = [round(x[0]) for x in predictions]\n",
    "# print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from resizeimage import resizeimage\n",
    "\n",
    "# img = Xtrain[1,:,:]\n",
    "# new_img = resizeimage.resize_width(img, 7)\n",
    "# plt.imshow(new_img)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
