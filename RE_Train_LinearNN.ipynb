{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST and some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAB6CAYAAAC7kYnCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF4GsG9AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d62e93510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]\n",
    "\n",
    "# split train data in two parts\n",
    "X_pr = Xtrain[30000:60000, :, :]\n",
    "Y_pr = Ytrain[30000:60000]\n",
    "\n",
    "Xtrain = Xtrain[0:30000, :, :];\n",
    "Ytrain = Ytrain[0:30000]\n",
    "\n",
    "# DOWNSAMPLE THE IMAGES\n",
    "factor = 0.25\n",
    "\n",
    "Xtrain_down = np.ones((Xtrain.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    Xtrain_down[i, :, :] = imresize(Xtrain[i,:,:], factor)\n",
    "\n",
    "Xtest_down = np.ones((Xtest.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtest.shape[0]):\n",
    "    Xtest_down[i,:,:] = imresize(Xtest[i,:,:], factor)\n",
    "\n",
    "    \n",
    "X_pr_down = np.ones((X_pr.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(X_pr.shape[0]):\n",
    "    X_pr_down[i,:,:] = imresize(X_pr[i,:,:], factor)\n",
    "\n",
    "    \n",
    "# VECTORIZE IMAGES\n",
    "Xtrain_down = Xtrain_down.reshape(Xtrain.shape[0], int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtest_down  = Xtest_down.reshape(ntest, int(xdim*factor)**2).astype('float32') / 255\n",
    "X_pr_down   = X_pr_down.reshape(X_pr.shape[0], int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtrain      = Xtrain.reshape(Xtrain.shape[0], xdim**2).astype('float32') / 255\n",
    "Xtest       = Xtest.reshape(ntest, xdim**2).astype('float32') / 255\n",
    "\n",
    "# Categorical labels\n",
    "Ytrain_cat = np_utils.to_categorical(Ytrain, 10)\n",
    "Ytest_cat = np_utils.to_categorical(Ytest, 10)\n",
    "\n",
    "# VISUALIZATION 20 RANDOM TRAINING SAMPLES\n",
    "# Create 20 subplots\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        axes[i][j].imshow(Xtrain_down[np.random.randint(0, 3000),:].reshape(int(xdim*factor), \n",
    "                          int(ydim*factor)), cmap='gray_r', interpolation='nearest')\n",
    "        axes[i][j].set_xticks([])\n",
    "        axes[i][j].set_yticks([])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN A FULLY-CONNECTED NN WITH 4 \"LINEAR\" HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30000/30000 [==============================] - 5s - loss: 9.3614 - acc: 0.1273     \n",
      "Epoch 2/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 3/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 4/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 5/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 6/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 7/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 8/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 9/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 10/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 11/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 12/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 13/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 14/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 15/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 16/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 17/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 18/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 19/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 20/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 21/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 22/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 23/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 24/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 25/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 26/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 27/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 28/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 29/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 30/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 31/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 32/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 33/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 34/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 35/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 36/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 37/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 38/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 39/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 40/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 41/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 42/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 43/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 44/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 45/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 46/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 47/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 48/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 49/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "Epoch 50/50\n",
      "30000/30000 [==============================] - 3s - loss: 9.4645 - acc: 0.1259     \n",
      "\n",
      "acc: 12.95%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(int(xdim*factor)**2,)))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "with tf.device('/gpu:1'):\n",
    "    model.fit(Xtrain_down, Ytrain_cat, nb_epoch=50, batch_size=32)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(Xtest_down, Ytest_cat, verbose=0)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# # calculate predictions\n",
    "# Ypredict = model.predict(Xtest)\n",
    "# # round predictions\n",
    "# rounded = [round(x[0]) for x in Ypredict]\n",
    "# print(rounded)\n",
    "\n",
    "# Save the model\n",
    "model.save('linear_nn.h5')\n",
    "\n",
    "# GET THE OUTPUT OF EACH LAYER AFTER TRAINING\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function\n",
    "layer_outs = functor([X_pr_down, 1.])                       # compute on 2nd training set\n",
    "layer_outs_test = functor([Xtest_down, 1.])                 # compute on test set\n",
    "#print(layer_outs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('linear_NN_layer_outputs.dat','wb') as f:\n",
    "    pickle.dump([layer_outs, layer_outs_test], f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
