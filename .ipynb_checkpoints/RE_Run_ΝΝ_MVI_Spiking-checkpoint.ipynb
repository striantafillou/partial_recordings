{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "m1_imported = scipy.io.loadmat('/home/klab/Public/Stevenson_50ms.mat')\n",
    "data = pd.DataFrame()\n",
    "data['time'] =  m1_imported['time'][:,0]\n",
    "data['handPos_x'] =  m1_imported['handPos'][:,0]\n",
    "data['handPos_y'] =  m1_imported['handPos'][:,1]\n",
    "data['handVel_x'] =  m1_imported['handVel'][:,0]\n",
    "data['handVel_y'] =  m1_imported['handVel'][:,1]\n",
    "\n",
    "X = m1_imported['spikes']\n",
    "Y = m1_imported['handVel']\n",
    "\n",
    "testSamples  = range(0,1554)\n",
    "trainSamples = range(1554, Y.shape[0])   \n",
    "\n",
    "X_test = X[testSamples, :]\n",
    "Y_test = Y[testSamples, :]\n",
    "# print(X_test.shape,Y_test.shape)\n",
    "X_train = X[trainSamples, :]\n",
    "Y_train = Y[trainSamples, :]\n",
    "# print(X_train.shape,Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Neural Networks and average outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "('zero cols=', array([], dtype=int64), '#Total cols=', 10)\n"
     ]
    }
   ],
   "source": [
    "from copy import copy, deepcopy\n",
    "from RE_PartialRecData2 import RE_PartialRecData2\n",
    "from sklearn import preprocessing, linear_model\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from sklearn.metrics import coverage_error\n",
    "from fancyimpute import SoftImpute\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "# how many recordings?\n",
    "nRecordings = 10\n",
    "# how many iterations\n",
    "nIterations = 5\n",
    "\n",
    "# how many neurons from the firs hidden layer?\n",
    "subnetSize = [2**x for x in range(8)]\n",
    "subnetSize.append(172)\n",
    "nSubnetSize = len(subnetSize)\n",
    "# how many samples per recording?\n",
    "nSamples = np.divide(int(X_train.shape[0]/nRecordings),subnetSize)*100\n",
    "nOutNeurons = 2\n",
    "rmses = np.zeros([nIterations, nOutNeurons, nSubnetSize])    \n",
    "    \n",
    "for ss in range(len(subnetSize)):\n",
    "    nLayerNeurons = subnetSize[ss]\n",
    "    print(subnetSize[ss]) \n",
    "\n",
    "    for it in range(nIterations):\n",
    "        start = time.time()         \n",
    "        # subsample\n",
    "        X_subsample, Y_subsample = RE_PartialRecData2(X_train, Y_train, nLayerNeurons, nRecordings, nSamples[ss])\n",
    "\n",
    "        # impute X_subsample with mean value, apply imputation to test set\n",
    "        imp = preprocessing.Imputer(missing_values='NaN', strategy='mean')\n",
    "        impf = imp.fit(X_subsample)\n",
    "        X_new = impf.transform(X_subsample)\n",
    "        X_test_new = impf.transform(X_test)\n",
    "        \n",
    "        # remove zero-cols\n",
    "        (ZZ,) = np.where(~X_new.any(axis=0))\n",
    "        print('zero cols=', ZZ, '#Total cols=', X_new.shape[1])\n",
    "        (NZ,) = np.where(X_new.any(axis=0))\n",
    "        X_new = X_new[:,NZ]\n",
    "        X_test_new = X_test_new[:,NZ]\n",
    "\n",
    "#         # subsample\n",
    "#         X_subsample, Y_subsample = RE_PartialRecData2(X_train, Y_train, nLayerNeurons, nRecordings, nSamples[ss])\n",
    "#         (keep_cols,) = np.where(~np.all(np.isnan(X_subsample), axis=0))\n",
    "\n",
    "#         # impute X_subsample with soft impute\n",
    "#         if ss==nSubnetSize-1:\n",
    "#             X_new = X_subsample[:,keep_cols]\n",
    "#         else:\n",
    "#             X_new = SoftImpute(convergence_threshold=0.01, max_iters=30).complete(X_subsample[:, keep_cols])\n",
    "\n",
    "#         X_test_new = X_test[:, keep_cols]\n",
    "\n",
    "        # fit ΝΝ\n",
    "        model = Sequential()\n",
    "        model.add(Dense(16, input_shape=(X_new.shape[1],), activation='relu'))#, W_regularizer=regularizers.l1(0.01)))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(16, activation='relu'))                \n",
    "        model.add(Dense(2, activation='tanh'))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, verbose=0)]\n",
    "        model.fit(X_new, Y_subsample, epochs=100, batch_size=16, shuffle=True, verbose=0, \n",
    "                  validation_split=0.1, callbacks=callbacks)\n",
    "#         model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#         model.fit(X_new, Y_subsample, nb_epoch=50, batch_size=8, verbose=0)\n",
    "\n",
    "        stop = time.time()\n",
    "        duration = stop-start\n",
    "        print(duration)\n",
    "        rmses[it,:,ss] = np.sqrt(np.mean((model.predict(X_test_new) - Y_test)**2, axis=0))\n",
    "        \n",
    "        # evaluate the model\n",
    "#         rmses[it,:,ss] = model.evaluate(X_test_new, Y_test, verbose=0)[1]*100\n",
    "#     print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], np.mean(rmses[it,:,ss])))\n",
    "    \n",
    "    print ('predicting, mean RMSEs=%f' %np.mean(rmses[it, :, ss]))\n",
    "\n",
    "\n",
    "fName = 'results/NNMVI_RMSES_nRec' + str(nRecordings) + '_Spiking_NZ.dat'\n",
    "with open(fName,'wb') as f:\n",
    "    pickle.dump(rmses, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = [2**x for x in range(8)]\n",
    "x.append(172)\n",
    "xx = range(len(x))\n",
    "y = np.median(np.median(rmses, axis=1), axis=0)\n",
    "error = np.std(np.mean(rmses, axis=1), axis=0)\n",
    "\n",
    "figName = '../partial_recordings/figures/NNMVI_RMSEs_Spiking_NZ'\n",
    "fig, ax1 = plt.subplots(1,1, figsize=(8, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .35, wspace=.15)\n",
    "ax1.plot(x, y, linewidth=2.5, color='m')\n",
    "plt.fill_between(x, y-error, y+error, alpha=0.2, color='m')\n",
    "\n",
    "ax1.annotate('#Observed neurons=172', xy=(x[-1], y[-1]), xytext=(256, y[-2]),\\\n",
    "             fontsize=14, arrowprops=dict(facecolor='g', shrink=0.05))\n",
    "\n",
    "ax1.set_xscale('log', basex=2)\n",
    "ax1.set_xlabel('# observed neurons', fontsize=20)\n",
    "ax1.set_xlim([1,2**8])\n",
    "ax1.set_xticks([2**x for x in range(9)])\n",
    "ax1.set_xticklabels( [2**x for x in range(9)], fontsize=14)\n",
    "ax1.set_ylabel('RMSE', fontsize=20)\n",
    "ylim = ax1.get_ylim()\n",
    "ax1.set_ylim(ylim)\n",
    "ax1.tick_params('both', labelsize=14)\n",
    "\n",
    "plt.draw()\n",
    "plt.savefig(figName +'.pdf', format='pdf')\n",
    "plt.savefig(figName +'.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
