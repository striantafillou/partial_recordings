{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('linear_NN_layer_outputs.dat','rb') as f:\n",
    "    layer_outs,layer_outs_test= pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load recording and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from scipy.misc import imresize\n",
    "\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]\n",
    "\n",
    "# Recording data\n",
    "X_pr = Xtrain[30000:60000, :, :]\n",
    "Y_pr = Ytrain[30000:60000]\n",
    "\n",
    "# downsample\n",
    "factor = 0.25\n",
    "\n",
    "Xtest_down = np.ones((Xtest.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtest.shape[0]):\n",
    "    Xtest_down[i,:,:] = imresize(Xtest[i,:,:], factor)\n",
    "\n",
    "X_pr_down = np.ones((X_pr.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(X_pr.shape[0]):\n",
    "    X_pr_down[i,:,:] = imresize(X_pr[i,:,:], factor)\n",
    "    \n",
    "# VECTORIZE IMAGES\n",
    "Xtest_down = Xtest_down.reshape(ntest, int(xdim*factor)**2).astype('float32') / 255\n",
    "X_pr_down = X_pr_down.reshape(X_pr_down.shape[0], int(xdim*factor)**2).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Multiple Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "predicting, mean RMSEs=0.000000\n",
      "predicting, mean RMSEs=0.000000\n",
      "predicting, mean RMSEs=0.000000\n",
      "predicting, mean RMSEs=0.000000\n",
      "predicting, mean RMSEs=0.000000\n"
     ]
    }
   ],
   "source": [
    "from copy import copy, deepcopy\n",
    "from RE_PartialRecData2 import RE_PartialRecData2\n",
    "from sklearn import preprocessing, linear_model\n",
    "import pickle\n",
    "\n",
    "\n",
    "# how many recordings?\n",
    "nRecordings = 10\n",
    "# how many neurons from the firs hidden layer?\n",
    "#subnetSize = [2**x for x in range(8)]\n",
    "subnetSize =[128]\n",
    "nSubnetSize = len(subnetSize)\n",
    "# which layers?\n",
    "iLayer=3\n",
    "# how many samples per recording?\n",
    "nSamples = np.divide(int(X_pr_down.shape[0]/nRecordings),subnetSize)*100\n",
    "#nSamples=[100 for i in range(nSubnetSize)]\n",
    "# how many iterations\n",
    "nIterations = 5\n",
    "\n",
    "# baseline prediction error\n",
    "#bl = np.std(layer_outs_test[oLayer]-np.mean(layer_outs_test[oLayer]));\n",
    "\n",
    "oLayer = len(layer_outs)-1  # index of output layer\n",
    "nOutNeurons = layer_outs[oLayer].shape[1]\n",
    "rmses = np.zeros([nIterations, nOutNeurons, nSubnetSize])\n",
    "for ss in range(nSubnetSize):\n",
    "    r_coefs =np.zeros((nIterations, 10, 128))\n",
    "    #nLayerNeurons = [subnetSize[ss], 0, 0, 0, 10]\n",
    "    nLayerNeurons = subnetSize[ss]\n",
    "    print(subnetSize[ss])\n",
    "    for it in range(nIterations):\n",
    "        # copy data - is this necessary?\n",
    "        layer_outputs = deepcopy(layer_outs)\n",
    "        # subsample\n",
    "        X_subsample, Y_subsample = RE_PartialRecData2(layer_outputs[iLayer], layer_outputs[oLayer], \\\n",
    "                                                      nLayerNeurons, nRecordings, nSamples[ss])\n",
    "        # impute X_subsample with mean value, apply imputation to test set\n",
    "        imp =preprocessing.Imputer(missing_values='NaN', strategy='mean')\n",
    "        impf =imp.fit(X_subsample)\n",
    "        X_new = impf.transform(X_subsample)\n",
    "        X_test_new= impf.transform(layer_outs_test[iLayer])\n",
    "        # fit regression model\n",
    "        #regr = linear_model.Lasso(0.01)\n",
    "        regr =linear_model.LinearRegression()\n",
    "        regr.fit(X_new, Y_subsample)\n",
    "        r_coefs[it,:, ]=regr.coef_\n",
    "        # calculate rmse\n",
    "        rmses[it,:,ss] = np.sqrt(np.mean((regr.predict(X_test_new) - layer_outs_test[oLayer])**2, axis=0))\n",
    " \n",
    "        print ('predicting, mean RMSEs=%f' %np.mean(rmses[it, :, ss]))\n",
    "#         if np.mean(rmses[it, :, ss])>1:\n",
    "#             breakflag=True\n",
    "#             break\n",
    "#     if breakflag:\n",
    "#         break\n",
    "\n",
    "            \n",
    "# # save the rmse's\n",
    "# with open('RMSE_Layer1_NLNN.dat','wb') as f:\n",
    "#     pickle.dump(rmses, f)\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "nn = load_model('linear_nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0153292\n",
      "0.0153292\n"
     ]
    }
   ],
   "source": [
    "a =nn.layers[0].get_weights()\n",
    "a[0].shape# b = nn.layers[4].get_weights()\n",
    "print(np.sum(a[0][:,0]*Xtest_down[0, :])+a[1][0])\n",
    "print(layer_outs_test[0][0, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286002\n",
      "0.286003\n"
     ]
    }
   ],
   "source": [
    "a =nn.layers[3].get_weights()\n",
    "a[0].shape# b = nn.layers[4].get_weights()\n",
    "print(np.sum(a[0][:,0]*layer_outs_test[2][0, :])+a[1][0])\n",
    "print(layer_outs_test[3][0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00322389\n",
      "-0.0032239\n"
     ]
    }
   ],
   "source": [
    "a =nn.layers[1].get_weights()\n",
    "a[0].shape# b = nn.layers[4].get_weights()\n",
    "print(np.sum(a[0][:,0]*layer_outs_test[0][0, :])+a[1][0])\n",
    "print(layer_outs_test[1][0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4627\n",
      "-1.4627\n"
     ]
    }
   ],
   "source": [
    "a =nn.layers[4].get_weights()\n",
    "a[0].shape# b = nn.layers[4].get_weights()\n",
    "print(np.sum(a[0][:,0]*layer_outs_test[3][0, :])+a[1][0])\n",
    "print(layer_outs_test[4][0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969955986369\n",
      "0.970517073147\n",
      "0.968932918435\n",
      "0.961755356099\n",
      "0.967999772868\n"
     ]
    }
   ],
   "source": [
    "for i in range(nIterations):\n",
    "    c =np.corrcoef(r_coefs[i, 1, :], a[0][:, 1])\n",
    "    print(c[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,  1000.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.]),\n",
       " array([-0.5 , -0.49, -0.48, -0.47, -0.46, -0.45, -0.44, -0.43, -0.42,\n",
       "        -0.41, -0.4 , -0.39, -0.38, -0.37, -0.36, -0.35, -0.34, -0.33,\n",
       "        -0.32, -0.31, -0.3 , -0.29, -0.28, -0.27, -0.26, -0.25, -0.24,\n",
       "        -0.23, -0.22, -0.21, -0.2 , -0.19, -0.18, -0.17, -0.16, -0.15,\n",
       "        -0.14, -0.13, -0.12, -0.11, -0.1 , -0.09, -0.08, -0.07, -0.06,\n",
       "        -0.05, -0.04, -0.03, -0.02, -0.01,  0.  ,  0.01,  0.02,  0.03,\n",
       "         0.04,  0.05,  0.06,  0.07,  0.08,  0.09,  0.1 ,  0.11,  0.12,\n",
       "         0.13,  0.14,  0.15,  0.16,  0.17,  0.18,  0.19,  0.2 ,  0.21,\n",
       "         0.22,  0.23,  0.24,  0.25,  0.26,  0.27,  0.28,  0.29,  0.3 ,\n",
       "         0.31,  0.32,  0.33,  0.34,  0.35,  0.36,  0.37,  0.38,  0.39,\n",
       "         0.4 ,  0.41,  0.42,  0.43,  0.44,  0.45,  0.46,  0.47,  0.48,\n",
       "         0.49,  0.5 ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAFwCAYAAAAMgociAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwQg0AIDBCDQAgMEINACAwfx//p4Kj8oC5bIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ae3876110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "fig=pl.figure(figsize=(10,6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "pl.hist(X_test_new[:, 11], 100)\n",
    "pl.hist(X_new[:, 11], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nRecordings=10\n",
    "hLayerOuts =layer_outs[iLayer]\n",
    "nSamples = 20\n",
    "nLayerNeurons =64\n",
    "oLayerOuts = layer_outs[oLayer]\n",
    "import numpy as np\n",
    "# returns a data set where, nLayerNeurons are recorded from a hidden layer, for each of nRecordings.\n",
    "# Each partial recording has nSamples.\n",
    "layerArray = np.zeros((nRecordings, nLayerNeurons), dtype=int)\n",
    "for iRec in range(nRecordings):\n",
    "    layerArray[iRec, :]= np.sort(np.random.choice(range(hLayerOuts.shape[1]), size=nLayerNeurons, replace=False))      \n",
    "\n",
    "#print(layerArray)\n",
    "X = np.nan*np.zeros((nRecordings*nSamples, hLayerOuts.shape[1]))\n",
    "Y = np.nan*np.zeros((nRecordings*nSamples, oLayerOuts.shape[1]))\n",
    "\n",
    "# get the data\n",
    "sample_ind=0\n",
    "for iRec in range(nRecordings):\n",
    "    rec_inds = np.random.choice(range(hLayerOuts.shape[0]), size=nSamples, replace=True)\n",
    "    #print(rec_inds)\n",
    "    cols = layerArray[iRec, :]\n",
    "    cols = cols[:, None]\n",
    "    inds = np.array(range(sample_ind,((iRec+1)*nSamples)), dtype=int)\n",
    "    X[inds, cols] = hLayerOuts[rec_inds, cols]\n",
    "    Y[inds, :] = oLayerOuts[rec_inds, :]\n",
    "    sample_ind = sample_ind + nSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.85872451e-09   7.69069970e-07   1.02532972e-07   2.26339489e-06\n",
      "    4.99717726e-06   2.63526290e-09   7.92602356e-15   8.07757140e-04\n",
      "    9.92751666e-07   9.99183118e-01]\n",
      " [  1.12052190e-08   9.21405868e-11   3.21917189e-13   6.32738393e-12\n",
      "    2.99384837e-08   1.78120949e-10   1.33580783e-22   8.99196148e-01\n",
      "    4.44876025e-10   1.00803912e-01]\n",
      " [  3.82415441e-18   3.98676724e-14   1.53948832e-07   9.99999881e-01\n",
      "    8.23255078e-17   9.32785049e-09   6.76083625e-25   3.53728106e-16\n",
      "    2.15845050e-10   9.12062925e-11]\n",
      " [  1.70427283e-11   1.67193741e-11   1.53190498e-11   3.27679163e-06\n",
      "    1.58354636e-16   4.76516569e-12   2.94215730e-16   1.88558752e-11\n",
      "    9.99996305e-01   4.63654857e-07]\n",
      " [  1.27942126e-20   3.68153251e-12   4.48373469e-14   1.30678149e-10\n",
      "    9.75062824e-16   8.71371253e-15   9.60693259e-31   1.00000000e+00\n",
      "    2.32977221e-10   2.28983534e-11]\n",
      " [  2.07677570e-10   9.44446209e-14   1.37762859e-12   4.99024650e-14\n",
      "    3.19535154e-08   3.06370988e-12   1.00000000e+00   1.37054453e-23\n",
      "    2.22145219e-10   1.27808495e-12]\n",
      " [  2.25460053e-10   3.28388161e-09   9.47710022e-10   1.72050392e-07\n",
      "    1.24423377e-12   7.68069513e-05   5.68615877e-10   5.17839217e-14\n",
      "    9.99922872e-01   1.24885887e-07]\n",
      " [  4.24627019e-15   1.29367680e-11   4.00770124e-15   2.21419636e-11\n",
      "    2.42116437e-19   1.00000000e+00   7.67609448e-11   1.70148209e-19\n",
      "    2.42952325e-08   1.34838607e-11]\n",
      " [  1.00000000e+00   1.91100149e-25   1.64155356e-16   4.50925297e-20\n",
      "    4.79299838e-18   7.47660972e-23   4.70454465e-18   8.66346787e-22\n",
      "    2.29971003e-22   2.93382316e-13]\n",
      " [  2.67982147e-11   2.07815834e-10   8.29366754e-14   2.68452166e-12\n",
      "    1.00970496e-16   6.10927628e-08   2.24884156e-11   1.53800193e-16\n",
      "    9.99999881e-01   3.74321729e-09]\n",
      " [  3.35329524e-08   2.26607249e-08   2.22898588e-10   1.52332175e-10\n",
      "    2.08074931e-13   1.16621779e-09   2.95653335e-10   2.74289966e-12\n",
      "    1.00000000e+00   1.17102852e-08]\n",
      " [  6.94274505e-08   6.23036613e-06   2.01820167e-05   7.73124158e-01\n",
      "    4.45907133e-08   2.26839498e-01   1.37151606e-08   1.28300726e-09\n",
      "    6.78708886e-07   9.17616853e-06]\n",
      " [  8.15568666e-04   4.32753779e-08   2.10064209e-05   8.09700794e-07\n",
      "    1.47606275e-04   7.21328206e-08   9.98978972e-01   1.14509704e-11\n",
      "    3.56648270e-05   3.11915699e-07]\n",
      " [  1.63221960e-22   1.00000000e+00   2.59102360e-15   1.77373188e-15\n",
      "    3.25745515e-15   3.51566629e-22   5.34332620e-18   6.58211635e-17\n",
      "    1.57616501e-14   3.55433471e-18]\n",
      " [  1.59502290e-11   2.54846498e-07   6.23075191e-09   5.97213955e-07\n",
      "    9.86136030e-04   6.94626712e-09   1.54436713e-10   6.13511872e-07\n",
      "    2.98670074e-07   9.99011993e-01]\n",
      " [  2.30602787e-28   4.44319135e-19   2.05210266e-14   1.00000000e+00\n",
      "    7.44172172e-24   4.47680426e-14   0.00000000e+00   3.62779509e-20\n",
      "    2.55933356e-15   3.27464711e-16]\n",
      " [  9.25867170e-27   1.97369078e-14   2.03607691e-08   8.85194063e-01\n",
      "    3.08039041e-24   1.79519125e-11   1.75054812e-37   1.14805967e-01\n",
      "    8.34592703e-13   2.14540621e-14]\n",
      " [  9.15614217e-21   1.39337527e-24   2.80939899e-22   1.90469609e-28\n",
      "    4.60733153e-15   3.90669083e-21   1.00000000e+00   0.00000000e+00\n",
      "    5.76845929e-19   4.49909115e-23]\n",
      " [  1.00000000e+00   2.57227991e-17   1.94327071e-13   6.02080252e-09\n",
      "    6.10946750e-18   3.83928354e-18   1.30627876e-13   7.67544041e-21\n",
      "    2.15140439e-15   8.98097135e-12]\n",
      " [  1.94920897e-08   7.13157589e-10   1.79852941e-05   6.95045092e-05\n",
      "    1.25239003e-05   8.05847378e-07   3.69203406e-08   2.60053696e-07\n",
      "    7.37032096e-05   9.99825180e-01]]\n",
      "[[  1.85872451e-09   7.69069970e-07   1.02532972e-07   2.26339489e-06\n",
      "    4.99717726e-06   2.63526290e-09   7.92602356e-15   8.07757140e-04\n",
      "    9.92751666e-07   9.99183118e-01]\n",
      " [  1.12052190e-08   9.21405868e-11   3.21917189e-13   6.32738393e-12\n",
      "    2.99384837e-08   1.78120949e-10   1.33580783e-22   8.99196148e-01\n",
      "    4.44876025e-10   1.00803912e-01]\n",
      " [  3.82415441e-18   3.98676724e-14   1.53948832e-07   9.99999881e-01\n",
      "    8.23255078e-17   9.32785049e-09   6.76083625e-25   3.53728106e-16\n",
      "    2.15845050e-10   9.12062925e-11]\n",
      " [  1.70427283e-11   1.67193741e-11   1.53190498e-11   3.27679163e-06\n",
      "    1.58354636e-16   4.76516569e-12   2.94215730e-16   1.88558752e-11\n",
      "    9.99996305e-01   4.63654857e-07]\n",
      " [  1.27942126e-20   3.68153251e-12   4.48373469e-14   1.30678149e-10\n",
      "    9.75062824e-16   8.71371253e-15   9.60693259e-31   1.00000000e+00\n",
      "    2.32977221e-10   2.28983534e-11]\n",
      " [  2.07677570e-10   9.44446209e-14   1.37762859e-12   4.99024650e-14\n",
      "    3.19535154e-08   3.06370988e-12   1.00000000e+00   1.37054453e-23\n",
      "    2.22145219e-10   1.27808495e-12]\n",
      " [  2.25460053e-10   3.28388161e-09   9.47710022e-10   1.72050392e-07\n",
      "    1.24423377e-12   7.68069513e-05   5.68615877e-10   5.17839217e-14\n",
      "    9.99922872e-01   1.24885887e-07]\n",
      " [  4.24627019e-15   1.29367680e-11   4.00770124e-15   2.21419636e-11\n",
      "    2.42116437e-19   1.00000000e+00   7.67609448e-11   1.70148209e-19\n",
      "    2.42952325e-08   1.34838607e-11]\n",
      " [  1.00000000e+00   1.91100149e-25   1.64155356e-16   4.50925297e-20\n",
      "    4.79299838e-18   7.47660972e-23   4.70454465e-18   8.66346787e-22\n",
      "    2.29971003e-22   2.93382316e-13]\n",
      " [  2.67982147e-11   2.07815834e-10   8.29366754e-14   2.68452166e-12\n",
      "    1.00970496e-16   6.10927628e-08   2.24884156e-11   1.53800193e-16\n",
      "    9.99999881e-01   3.74321729e-09]\n",
      " [  3.35329524e-08   2.26607249e-08   2.22898588e-10   1.52332175e-10\n",
      "    2.08074931e-13   1.16621779e-09   2.95653335e-10   2.74289966e-12\n",
      "    1.00000000e+00   1.17102852e-08]\n",
      " [  6.94274505e-08   6.23036613e-06   2.01820167e-05   7.73124158e-01\n",
      "    4.45907133e-08   2.26839498e-01   1.37151606e-08   1.28300726e-09\n",
      "    6.78708886e-07   9.17616853e-06]\n",
      " [  8.15568666e-04   4.32753779e-08   2.10064209e-05   8.09700794e-07\n",
      "    1.47606275e-04   7.21328206e-08   9.98978972e-01   1.14509704e-11\n",
      "    3.56648270e-05   3.11915699e-07]\n",
      " [  1.63221960e-22   1.00000000e+00   2.59102360e-15   1.77373188e-15\n",
      "    3.25745515e-15   3.51566629e-22   5.34332620e-18   6.58211635e-17\n",
      "    1.57616501e-14   3.55433471e-18]\n",
      " [  1.59502290e-11   2.54846498e-07   6.23075191e-09   5.97213955e-07\n",
      "    9.86136030e-04   6.94626712e-09   1.54436713e-10   6.13511872e-07\n",
      "    2.98670074e-07   9.99011993e-01]\n",
      " [  2.30602787e-28   4.44319135e-19   2.05210266e-14   1.00000000e+00\n",
      "    7.44172172e-24   4.47680426e-14   0.00000000e+00   3.62779509e-20\n",
      "    2.55933356e-15   3.27464711e-16]\n",
      " [  9.25867170e-27   1.97369078e-14   2.03607691e-08   8.85194063e-01\n",
      "    3.08039041e-24   1.79519125e-11   1.75054812e-37   1.14805967e-01\n",
      "    8.34592703e-13   2.14540621e-14]\n",
      " [  9.15614217e-21   1.39337527e-24   2.80939899e-22   1.90469609e-28\n",
      "    4.60733153e-15   3.90669083e-21   1.00000000e+00   0.00000000e+00\n",
      "    5.76845929e-19   4.49909115e-23]\n",
      " [  1.00000000e+00   2.57227991e-17   1.94327071e-13   6.02080252e-09\n",
      "    6.10946750e-18   3.83928354e-18   1.30627876e-13   7.67544041e-21\n",
      "    2.15140439e-15   8.98097135e-12]\n",
      " [  1.94920897e-08   7.13157589e-10   1.79852941e-05   6.95045092e-05\n",
      "    1.25239003e-05   8.05847378e-07   3.69203406e-08   2.60053696e-07\n",
      "    7.37032096e-05   9.99825180e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(oLayerOuts[rec_inds, :])\n",
    "print(Y[inds, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
