{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# Load MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]\n",
    "\n",
    "# split train data in two\n",
    "X_pr = Xtrain[30000:60000, :, :]\n",
    "Y_pr = Ytrain[30000:60000]\n",
    "\n",
    "Xtrain = Xtrain[0:30000, :, :];\n",
    "Ytrain = Ytrain[0:30000]\n",
    "\n",
    "# downsample\n",
    "factor = 0.25\n",
    "\n",
    "Xtrain_down = np.ones((Xtrain.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    Xtrain_down[i, :, :] = imresize(Xtrain[i,:,:], factor)\n",
    "\n",
    "Xtest_down = np.ones((Xtest.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtest.shape[0]):\n",
    "    Xtest_down[i,:,:] = imresize(Xtest[i,:,:], factor)\n",
    "\n",
    "X_pr_down = np.ones((X_pr.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(X_pr.shape[0]):\n",
    "    X_pr_down[i,:,:] = imresize(X_pr[i,:,:], factor)\n",
    "    \n",
    "# *** VECTORIZE IMAGES ***\n",
    "Xtrain_down = Xtrain_down.reshape(Xtrain_down.shape[0], int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtest_down = Xtest_down.reshape(ntest, int(xdim*factor)**2).astype('float32') / 255\n",
    "X_pr_down = X_pr_down.reshape(X_pr_down.shape[0], int(xdim*factor)**2).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load NN and get output values\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('nn.h5')\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function\n",
    "\n",
    "# Testing: layer_outs is a list with 4 data sets\n",
    "layer_outs = functor([X_pr_down, 1.])\n",
    "\n",
    "layer_outs_test= functor([Xtest_down, 1.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsample and do xgboost regression\n",
    "from copy import copy, deepcopy\n",
    "from RE_PartialRecData import RE_PartialRecData\n",
    "\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# setup parameters for xgboost\n",
    "params = {}\n",
    "# use softmax multi-class classification 'multi:softmax'\n",
    "# use linear regression 'reg:linear'\n",
    "params['objective'] = 'reg:linear'\n",
    "# scale weight of positive examples\n",
    "params['eta'] = 0.1\n",
    "params['max_depth'] = 3\n",
    "params['silent'] = 1\n",
    "params['nthread'] = 4\n",
    "# params['num_class'] = 10\n",
    "num_round=5\n",
    "\n",
    "# how many recordings?\n",
    "nRecordings = 10\n",
    "# how many neurons from the firs hidden layer?\n",
    "subnetSize = range(1,51,5)\n",
    "nSubnetSize = len(subnetSize)\n",
    "# which layers?\n",
    "# how many samples per recording?\n",
    "nSamples = int(X_pr_down.shape[0]/nRecordings)\n",
    "# how many iterations\n",
    "nIterations = 5\n",
    "\n",
    "oLayer = len(layer_outs)-1\n",
    "nOutNeurons = layer_outs[oLayer].shape[1]\n",
    "rmses = np.zeros([nIterations, nOutNeurons, nSubnetSize])\n",
    "\n",
    "for ss in range(nSubnetSize):\n",
    "    nLayerNeurons = [subnetSize[ss], 0, 0, 10]\n",
    "    for it in range(nIterations):\n",
    "        #print(nLayerNeurons, iter)\n",
    "        # copy data\n",
    "        layer_outputs = deepcopy(layer_outs)\n",
    "        # subsample\n",
    "        X = RE_PartialRecData(layer_outputs, nLayerNeurons, nRecordings, nSamples)\n",
    "        # prepare data for xgboost\n",
    "        xg_train = xgb.DMatrix(X, label=Y_pr)\n",
    "        xg_test  = xgb.DMatrix(layer_outs_test[0], label=Ytest)\n",
    "        watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "        for iN in range(nOutNeurons):\n",
    "            print(iN)\n",
    "            xg_train  = xgb.DMatrix(X, label=layer_outs[3][:,iN])\n",
    "            xg_test   = xgb.DMatrix(layer_outs_test[0], label=layer_outs_test[3][:,iN])\n",
    "            watchlist = [(xg_train,'train'), (xg_test, 'test')]\n",
    "\n",
    "            bst = xgb.train(params, xg_train, num_round, watchlist);\n",
    "            # get prediction\n",
    "            pred = bst.predict( xg_test );\n",
    "            rmses[it,iN,ss] = np.sqrt(sum(np.square(pred[i] -layer_outs_test[3][:,1][i]) \n",
    "                                          for i in range(len(layer_outs_test[3][:,1]))) / float(len(layer_outs_test[3][:,1])))\n",
    "            print ('predicting, RMSE=%f' %rmses[it, iN,ss ] )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the rmse's\n",
    "import pickle\n",
    "\n",
    "with open('RMSE.dat','wb') as f:\n",
    "    pickle.dump(rmses, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.mean(rmses, axis=0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
