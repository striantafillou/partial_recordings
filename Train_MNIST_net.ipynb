{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# Load MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
    "\n",
    "(ntrain, xdim, ydim) = Xtrain.shape\n",
    "ntest = Xtest.shape[0]\n",
    "\n",
    "# split train data in two\n",
    "X_pr = Xtrain[30001:60000, :, :]\n",
    "Y_pr = Ytrain[30001:60000]\n",
    "\n",
    "Xtrain = Xtrain[0:30000, :, :];\n",
    "Ytrain = Ytrain[0:30000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# *** DOWNSAMPLE THE IMAGES ***\n",
    "factor = 0.25\n",
    "\n",
    "Xtrain_down = np.ones((Xtrain.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    Xtrain_down[i, :, :] = imresize(Xtrain[i,:,:], factor)\n",
    "\n",
    "Xtest_down = np.ones((Xtest.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(Xtest.shape[0]):\n",
    "    Xtest_down[i,:,:] = imresize(Xtest[i,:,:], factor)\n",
    "\n",
    "    \n",
    "X_pr_down = np.ones((X_pr.shape[0], int(xdim*factor), int(ydim*factor)))\n",
    "for i in range(X_pr.shape[0]):\n",
    "    X_pr_down[i,:,:] = imresize(X_pr[i,:,:], factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# *** VECTORIZE IMAGES ***\n",
    "Xtrain_down = Xtrain_down.reshape(ntrain, int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtest_down = Xtest_down.reshape(ntest, int(xdim*factor)**2).astype('float32') / 255\n",
    "Xtrain = Xtrain.reshape(ntrain, xdim**2).astype('float32') / 255\n",
    "Xtest = Xtest.reshape(ntest, xdim**2).astype('float32') / 255\n",
    "# Categorical labels\n",
    "Ytrain = np_utils.to_categorical(Ytrain, 10)\n",
    "Ytest = np_utils.to_categorical(Ytest, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAB6CAYAAAC7kYnCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCN6/AGQsaJpBzrcDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a23f81910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# *** VISUALIZATION 20 RANDOM TRAINING SAMPLES ***\n",
    "# Create 20 subplots\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        axes[i][j].imshow(Xtrain_down[np.random.randint(0, 6000),:].reshape(int(xdim*factor), \n",
    "                          int(ydim*factor)), cmap='gray_r', interpolation='nearest')\n",
    "        axes[i][j].set_xticks([])\n",
    "        axes[i][j].set_yticks([])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # *** LDA ***\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# # Original images\n",
    "# clf = LinearDiscriminantAnalysis()\n",
    "# clf.fit(Xtrain, Ytrain)\n",
    "# LinearDiscriminantAnalysis(n_components=9, priors=None, shrinkage=None,\n",
    "#               solver='svd', store_covariance=False, tol=0.0001)\n",
    "\n",
    "# # Returns the mean accuracy on the given test data and labels.\n",
    "# score = clf.score(Xtest, Ytest, sample_weight=None)\n",
    "# print(score)\n",
    "\n",
    "# # Down-sampled images\n",
    "# clf = LinearDiscriminantAnalysis()\n",
    "# clf.fit(Xtrain_down, Ytrain)\n",
    "# LinearDiscriminantAnalysis(n_components=9, priors=None, shrinkage=None,\n",
    "#               solver='svd', store_covariance=False, tol=0.0001)\n",
    "\n",
    "# # Returns the mean accuracy on the given test data and labels.\n",
    "# score = clf.score(Xtest_down, Ytest, sample_weight=None)\n",
    "# print(score)\n",
    "# # print(clf.predict(Xtest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.3334 - acc: 0.8981     \n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.1678 - acc: 0.9469     \n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.1371 - acc: 0.9560     \n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.1184 - acc: 0.9624     \n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.1055 - acc: 0.9661     \n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0972 - acc: 0.9683     \n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0892 - acc: 0.9709     \n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0816 - acc: 0.9725     \n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0762 - acc: 0.9749     \n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0721 - acc: 0.9758     \n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0667 - acc: 0.9774     \n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0622 - acc: 0.9794     \n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0585 - acc: 0.9801     \n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0575 - acc: 0.9801     \n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0526 - acc: 0.9826     \n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0512 - acc: 0.9826     \n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0482 - acc: 0.9834     \n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0458 - acc: 0.9842     \n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0432 - acc: 0.9849     \n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0421 - acc: 0.9855     \n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0402 - acc: 0.9862     \n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0382 - acc: 0.9862     \n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0360 - acc: 0.9875     \n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0368 - acc: 0.9871     \n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0344 - acc: 0.9879     \n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0334 - acc: 0.9882     \n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0314 - acc: 0.9889     \n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0308 - acc: 0.9893     \n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0302 - acc: 0.9893     \n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0287 - acc: 0.9903     \n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0280 - acc: 0.9898     \n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0272 - acc: 0.9904     \n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0259 - acc: 0.9907     \n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0262 - acc: 0.9908     \n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0237 - acc: 0.9917     \n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0245 - acc: 0.9918     \n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0255 - acc: 0.9914     \n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0247 - acc: 0.9914     \n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0215 - acc: 0.9921     \n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0240 - acc: 0.9917     \n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0211 - acc: 0.9929     \n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0202 - acc: 0.9929     \n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0218 - acc: 0.9921     \n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0210 - acc: 0.9931     \n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 8s - loss: 0.0208 - acc: 0.9929     \n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0217 - acc: 0.9928     \n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0191 - acc: 0.9935     \n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0183 - acc: 0.9940     \n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0188 - acc: 0.9932     \n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 7s - loss: 0.0183 - acc: 0.9940     \n",
      "\n",
      "acc: 97.56%\n"
     ]
    }
   ],
   "source": [
    "# *** TRAIN A FULLY-CONNECTED NN WITH TWO HIDDEN LAYERS ***\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(int(xdim*factor)**2,), activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(Xtrain_down, Ytrain, nb_epoch=50, batch_size=16)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(Xtest_down, Ytest, verbose=0)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# # calculate predictions\n",
    "# Ypredict = model.predict(Xtest)\n",
    "# # round predictions\n",
    "# rounded = [round(x[0]) for x in Ypredict]\n",
    "# print(rounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET THE OUTPUT OF EACH LAYER AFTER TRAINING\n",
    "from keras import backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "#functors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n",
    "functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function\n",
    "\n",
    "# Testing\n",
    "layer_outs = functor([Xtest_down, 1.])\n",
    "print(layer_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
